{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/asif/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the punkt tokenizer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentences for training\n",
    "sentences = [\n",
    "    \"Word embeddings are vectors.\",\n",
    "    \"They represent words in a continuous vector space.\",\n",
    "    \"Word2Vec is a popular technique in natural language processing.\",\n",
    "    \"It captures semantic relationships between words.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"word2vec_model.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access word vectors\n",
    "word_vectors = model.wv\n",
    "vector = word_vectors['word']  # Get the vector for the word 'word'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find similar words\n",
    "similar_words = word_vectors.most_similar('word', topn=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'word': [-4.9735666e-03 -1.2833046e-03  3.2806373e-03 -6.4140330e-03\n",
      " -9.7015891e-03 -9.2602335e-03  9.0206973e-03  5.3716935e-03\n",
      " -4.7882269e-03 -8.3296420e-03  1.2939513e-03  2.8780627e-03\n",
      " -1.2452841e-03  1.2708711e-03 -4.3213032e-03  4.7913659e-03\n",
      "  1.4751852e-03  8.8778250e-03 -9.9765137e-03 -5.2695703e-03\n",
      " -9.1028418e-03 -3.4791828e-04 -7.8573059e-03  5.0312411e-03\n",
      " -6.3968552e-03 -5.9528374e-03  5.0709103e-03 -8.1597688e-03\n",
      "  1.4552021e-03 -7.2395410e-03  9.8624220e-03  8.6337589e-03\n",
      "  1.7689526e-03  5.7885037e-03  4.5962157e-03 -5.9917830e-03\n",
      "  9.7569469e-03 -9.6822055e-03  8.0492580e-03  2.7563798e-03\n",
      " -3.0551220e-03 -3.5618627e-03  9.0719536e-03 -5.4409085e-03\n",
      "  8.1868721e-03 -6.0088872e-03  8.3913766e-03 -5.5549381e-04\n",
      "  7.9425992e-03 -3.1549716e-03  5.9792148e-03  8.8043455e-03\n",
      "  2.5438380e-03  1.3177490e-03  5.0391923e-03  8.0025224e-03\n",
      "  8.5680140e-03  8.4927725e-03  7.0525263e-03  8.0026500e-03\n",
      "  8.5997405e-03 -3.3091306e-05 -1.0037315e-03  1.6657913e-03\n",
      "  3.2734870e-06  6.8517687e-04 -8.6009372e-03 -9.5947310e-03\n",
      " -2.3146761e-03  8.9282002e-03 -3.6475873e-03 -6.9781933e-03\n",
      "  4.8793829e-03  1.0691178e-03  1.8510211e-03  3.6529566e-03\n",
      "  3.5206736e-03  5.7261218e-03  1.2343001e-03  8.4446312e-04\n",
      "  9.0452507e-03  2.7822172e-03 -4.7028554e-03  6.5421867e-03\n",
      "  5.2133119e-03  2.8705669e-03 -3.1378341e-03  3.3368361e-03\n",
      "  6.3642981e-03  7.0810402e-03  9.4116566e-04 -8.5317669e-03\n",
      "  2.5776148e-04  3.7042022e-04  3.9429818e-03 -9.4689596e-03\n",
      "  9.7078709e-03 -6.9722771e-03  5.7614399e-03 -9.4298720e-03]\n",
      "Similar words to 'word': [('natural', 0.10193939507007599), ('vector', 0.08790984749794006), ('embeddings', 0.07372596859931946)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print results\n",
    "print(\"Vector for 'word':\", vector)\n",
    "print(\"Similar words to 'word':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
